name: "SqueezeNet_Pedestrian_SSD_384x256_train(add_conv4_3_classification, delete sqrt(min*max) default box)"
layer {
  name: "data"
  type: "AnnotatedData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_value: 104
    mean_value: 117
    mean_value: 123
    resize_param {
      prob: 1
      resize_mode: WARP
      height: 256
      width: 384
      interp_mode: LINEAR
      interp_mode: AREA
      interp_mode: NEAREST
      interp_mode: CUBIC
      interp_mode: LANCZOS4
    }
    emit_constraint {
      emit_type: CENTER
    }
  }
  data_param {
    source: "L:/tyang/Pedestrian/Data_0922/train_lmdb"
    batch_size: 32
    backend: LMDB
  }
  annotated_data_param {
    batch_sampler {
      max_sample: 1
      max_trials: 1
    }
	batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.1
        min_object_coverage: 0.7
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2.0
      }
      sample_constraint {
        min_jaccard_overlap: 0.3
        min_object_coverage: 0.7
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1.0
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2.0
      }
      sample_constraint {
        min_jaccard_overlap: 0.5
        min_object_coverage: 0.7
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1.0
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2.0
      }
      sample_constraint {
        min_jaccard_overlap: 0.7
        min_object_coverage: 0.7
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1.0
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2.0
      }
      sample_constraint {
        min_jaccard_overlap: 0.9
        min_object_coverage: 0.7
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1.0
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2.0
      }
      sample_constraint {
        max_jaccard_overlap: 1
        min_object_coverage: 0.7
      }
      max_sample: 1
      max_trials: 50
    }
    label_map_file: "L:/tyang/Pedestrian/labelmap_VehicleFull.prototxt"
  }
}

layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 64
    kernel_size: 3
    stride: 2
    pad:1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu_conv1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name : "conv1_bn"
  type : "BatchNorm"  include { phase: TRAIN}
  batch_norm_param {
    use_global_stats: false 
    moving_average_fraction: 0.95
  }
  top : "pool1"
  bottom : "pool1"
}
layer {
  name : "conv1_bn"
  type : "BatchNorm"  include { phase: TEST}
  batch_norm_param {
    use_global_stats: true 
    moving_average_fraction: 0.95
  }
  top : "pool1"
  bottom : "pool1"
}
layer {
  name: "fire2/squeeze1x1"
  type: "Convolution"
  bottom: "pool1"
  top: "fire2/squeeze1x1"
  convolution_param {
    num_output: 16
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire2/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire2/squeeze1x1"
  top: "fire2/squeeze1x1"
}
layer {
  name: "fire2/expand1x1"
  type: "Convolution"
  bottom: "fire2/squeeze1x1"
  top: "fire2/expand1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire2/relu_expand1x1"
  type: "ReLU"
  bottom: "fire2/expand1x1"
  top: "fire2/expand1x1"
}
layer {
  name: "fire2/expand3x3"
  type: "Convolution"
  bottom: "fire2/squeeze1x1"
  top: "fire2/expand3x3"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire2/relu_expand3x3"
  type: "ReLU"
  bottom: "fire2/expand3x3"
  top: "fire2/expand3x3"
}
layer {
  name: "fire2/concat"
  type: "Concat"
  bottom: "fire2/expand1x1"
  bottom: "fire2/expand3x3"
  top: "fire2/concat"
}
layer {
  name : "fire2/concat_bn"
  type : "BatchNorm"  include { phase: TRAIN}
  batch_norm_param {
    use_global_stats: false 
    moving_average_fraction: 0.95
  }
  top : "fire2/concat"
  bottom : "fire2/concat"
}
layer {
  name : "fire2/concat_bn"
  type : "BatchNorm"  include { phase: TEST}
  batch_norm_param {
    use_global_stats: true 
    moving_average_fraction: 0.95
  }
  top : "fire2/concat"
  bottom : "fire2/concat"
}
layer {
  name: "fire3/squeeze1x1"
  type: "Convolution"
  bottom: "fire2/concat"
  top: "fire3/squeeze1x1"
  convolution_param {
    num_output: 16
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire3/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire3/squeeze1x1"
  top: "fire3/squeeze1x1"
}
layer {
  name: "fire3/expand1x1"
  type: "Convolution"
  bottom: "fire3/squeeze1x1"
  top: "fire3/expand1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire3/relu_expand1x1"
  type: "ReLU"
  bottom: "fire3/expand1x1"
  top: "fire3/expand1x1"
}
layer {
  name: "fire3/expand3x3"
  type: "Convolution"
  bottom: "fire3/squeeze1x1"
  top: "fire3/expand3x3"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire3/relu_expand3x3"
  type: "ReLU"
  bottom: "fire3/expand3x3"
  top: "fire3/expand3x3"
}
layer {
  name: "fire3/concat"
  type: "Concat"
  bottom: "fire3/expand1x1"
  bottom: "fire3/expand3x3"
  top: "fire3/concat"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "fire3/concat"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name : "fire3/concat_bn"
  type : "BatchNorm"  include { phase: TRAIN}
  batch_norm_param {
    use_global_stats: false 
    moving_average_fraction: 0.95
  }
  top : "pool3"
  bottom : "pool3"
}
layer {
  name : "fire3/concat_bn"
  type : "BatchNorm"  include { phase: TEST}
  batch_norm_param {
    use_global_stats: true 
    moving_average_fraction: 0.95
  }
  top : "pool3"
  bottom : "pool3"
}

layer {
  name: "fire4/squeeze1x1"
  type: "Convolution"
  bottom: "pool3"
  top: "fire4/squeeze1x1"
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire4/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire4/squeeze1x1"
  top: "fire4/squeeze1x1"
}
layer {
  name: "fire4/expand1x1"
  type: "Convolution"
  bottom: "fire4/squeeze1x1"
  top: "fire4/expand1x1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire4/relu_expand1x1"
  type: "ReLU"
  bottom: "fire4/expand1x1"
  top: "fire4/expand1x1"
}
layer {
  name: "fire4/expand3x3"
  type: "Convolution"
  bottom: "fire4/squeeze1x1"
  top: "fire4/expand3x3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire4/relu_expand3x3"
  type: "ReLU"
  bottom: "fire4/expand3x3"
  top: "fire4/expand3x3"
}
layer {
  name: "fire4/concat"
  type: "Concat"
  bottom: "fire4/expand1x1"
  bottom: "fire4/expand3x3"
  top: "fire4/concat"
}
layer {
  name : "fire4/concat_bn"
  type : "BatchNorm"  include { phase: TRAIN}
  batch_norm_param {
    use_global_stats: false 
    moving_average_fraction: 0.95
  }
  top : "fire4/concat"
  bottom : "fire4/concat"
}
layer {
  name : "fire4/concat_bn"
  type : "BatchNorm"  include { phase: TEST}
  batch_norm_param {
    use_global_stats: true 
    moving_average_fraction: 0.95
  }
  top : "fire4/concat"
  bottom : "fire4/concat"
}


layer {
  name: "fire5/squeeze1x1"
  type: "Convolution"
  bottom: "fire4/concat"
  top: "fire5/squeeze1x1"
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire5/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire5/squeeze1x1"
  top: "fire5/squeeze1x1"
}
layer {
  name: "fire5/expand1x1"
  type: "Convolution"
  bottom: "fire5/squeeze1x1"
  top: "fire5/expand1x1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire5/relu_expand1x1"
  type: "ReLU"
  bottom: "fire5/expand1x1"
  top: "fire5/expand1x1"
}
layer {
  name: "fire5/expand3x3"
  type: "Convolution"
  bottom: "fire5/squeeze1x1"
  top: "fire5/expand3x3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire5/relu_expand3x3"
  type: "ReLU"
  bottom: "fire5/expand3x3"
  top: "fire5/expand3x3"
}
layer {
  name: "fire5/concat"
  type: "Concat"
  bottom: "fire5/expand1x1"
  bottom: "fire5/expand3x3"
  top: "fire5/concat"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "fire5/concat"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name : "fire5/concat_bn"
  type : "BatchNorm"  include { phase: TRAIN}
  batch_norm_param {
    use_global_stats: false 
    moving_average_fraction: 0.95
  }
  top : "pool5"
  bottom : "pool5"
}
layer {
  name : "fire5/concat_bn"
  type : "BatchNorm"  include { phase: TEST}
  batch_norm_param {
    use_global_stats: true 
    moving_average_fraction: 0.95
  }
  top : "pool5"
  bottom : "pool5"
}

layer {
  name: "fire6/squeeze1x1"
  type: "Convolution"
  bottom: "pool5"
  top: "fire6/squeeze1x1"
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire6/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire6/squeeze1x1"
  top: "fire6/squeeze1x1"
}
layer {
  name: "fire6/expand1x1"
  type: "Convolution"
  bottom: "fire6/squeeze1x1"
  top: "fire6/expand1x1"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire6/relu_expand1x1"
  type: "ReLU"
  bottom: "fire6/expand1x1"
  top: "fire6/expand1x1"
}
layer {
  name: "fire6/expand3x3"
  type: "Convolution"
  bottom: "fire6/squeeze1x1"
  top: "fire6/expand3x3"
  convolution_param {
    num_output: 192
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire6/relu_expand3x3"
  type: "ReLU"
  bottom: "fire6/expand3x3"
  top: "fire6/expand3x3"
}
layer {
  name: "fire6/concat"
  type: "Concat"
  bottom: "fire6/expand1x1"
  bottom: "fire6/expand3x3"
  top: "fire6/concat"
}
layer {
  name : "fire6/concat_bn"
  type : "BatchNorm"  include { phase: TRAIN}
  batch_norm_param {
    use_global_stats: false 
    moving_average_fraction: 0.95
  }
  top : "fire6/concat"
  bottom : "fire6/concat"
}
layer {
  name : "fire6/concat_bn"
  type : "BatchNorm"  include { phase: TEST}
  batch_norm_param {
    use_global_stats: true 
    moving_average_fraction: 0.95
  }
  top : "fire6/concat"
  bottom : "fire6/concat"
}


layer {
  name: "fire7/squeeze1x1"
  type: "Convolution"
  bottom: "fire6/concat"
  top: "fire7/squeeze1x1"
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire7/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire7/squeeze1x1"
  top: "fire7/squeeze1x1"
}
layer {
  name: "fire7/expand1x1"
  type: "Convolution"
  bottom: "fire7/squeeze1x1"
  top: "fire7/expand1x1"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire7/relu_expand1x1"
  type: "ReLU"
  bottom: "fire7/expand1x1"
  top: "fire7/expand1x1"
}
layer {
  name: "fire7/expand3x3"
  type: "Convolution"
  bottom: "fire7/squeeze1x1"
  top: "fire7/expand3x3"
  convolution_param {
    num_output: 192
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire7/relu_expand3x3"
  type: "ReLU"
  bottom: "fire7/expand3x3"
  top: "fire7/expand3x3"
}
layer {
  name: "fire7/concat"
  type: "Concat"
  bottom: "fire7/expand1x1"
  bottom: "fire7/expand3x3"
  top: "fire7/concat"
}
layer {
  name : "fire7/concat_bn"
  type : "BatchNorm"  include { phase: TRAIN}
  batch_norm_param {
    use_global_stats: false 
    moving_average_fraction: 0.95
  }
  top : "fire7/concat"
  bottom : "fire7/concat"
}
layer {
  name : "fire7/concat_bn"
  type : "BatchNorm"  include { phase: TEST}
  batch_norm_param {
    use_global_stats: true 
    moving_average_fraction: 0.95
  }
  top : "fire7/concat"
  bottom : "fire7/concat"
}

layer {
  name: "fire8/squeeze1x1"
  type: "Convolution"
  bottom: "fire7/concat"
  top: "fire8/squeeze1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire8/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire8/squeeze1x1"
  top: "fire8/squeeze1x1"
}
layer {
  name: "fire8/expand1x1"
  type: "Convolution"
  bottom: "fire8/squeeze1x1"
  top: "fire8/expand1x1"
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire8/relu_expand1x1"
  type: "ReLU"
  bottom: "fire8/expand1x1"
  top: "fire8/expand1x1"
}
layer {
  name: "fire8/expand3x3"
  type: "Convolution"
  bottom: "fire8/squeeze1x1"
  top: "fire8/expand3x3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire8/relu_expand3x3"
  type: "ReLU"
  bottom: "fire8/expand3x3"
  top: "fire8/expand3x3"
}
layer {
  name: "fire8/concat"
  type: "Concat"
  bottom: "fire8/expand1x1"
  bottom: "fire8/expand3x3"
  top: "fire8/concat"
}
layer {
  name : "fire8/concat_bn"
  type : "BatchNorm"  include { phase: TRAIN}
  batch_norm_param {
    use_global_stats: false 
    moving_average_fraction: 0.95
  }
  top : "fire8/concat"
  bottom : "fire8/concat"
}
layer {
  name : "fire8/concat_bn"
  type : "BatchNorm"  include { phase: TEST}
  batch_norm_param {
    use_global_stats: true 
    moving_average_fraction: 0.95
  }
  top : "fire8/concat"
  bottom : "fire8/concat"
}

layer {
  name: "fire9/squeeze1x1"
  type: "Convolution"
  bottom: "fire8/concat"
  top: "fire9/squeeze1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire9/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire9/squeeze1x1"
  top: "fire9/squeeze1x1"
}
layer {
  name: "fire9/expand1x1"
  type: "Convolution"
  bottom: "fire9/squeeze1x1"
  top: "fire9/expand1x1"
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire9/relu_expand1x1"
  type: "ReLU"
  bottom: "fire9/expand1x1"
  top: "fire9/expand1x1"
}
layer {
  name: "fire9/expand3x3"
  type: "Convolution"
  bottom: "fire9/squeeze1x1"
  top: "fire9/expand3x3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire9/relu_expand3x3"
  type: "ReLU"
  bottom: "fire9/expand3x3"
  top: "fire9/expand3x3"
}
layer {
  name: "fire9/concat"
  type: "Concat"
  bottom: "fire9/expand1x1"
  bottom: "fire9/expand3x3"
  top: "fire9/concat"
}
layer {
  name : "fire9/concat_bn"
  type : "BatchNorm"  include { phase: TRAIN}
  batch_norm_param {
    use_global_stats: false 
    moving_average_fraction: 0.95
  }
  top : "fire9/concat"
  bottom : "fire9/concat"
}
layer {
  name : "fire9/concat_bn"
  type : "BatchNorm"  include { phase: TEST}
  batch_norm_param {
    use_global_stats: true 
    moving_average_fraction: 0.95
  }
  top : "fire9/concat"
  bottom : "fire9/concat"
}

layer {
  name: "conv6_1"
  type: "Convolution"
  bottom: "fire9/concat"
  top: "conv6_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_1_relu"
  type: "ReLU"
  bottom: "conv6_1"
  top: "conv6_1"
}
layer {
  name : "conv6_1_bn"
  type : "BatchNorm"  include { phase: TRAIN}
  batch_norm_param {
    use_global_stats: false 
    moving_average_fraction: 0.95
  }
  top : "conv6_1"
  bottom : "conv6_1"
}
layer {
  name : "conv6_1_bn"
  type : "BatchNorm"  include { phase: TEST}
  batch_norm_param {
    use_global_stats: true 
    moving_average_fraction: 0.95
  }
  top : "conv6_1"
  bottom : "conv6_1"
}
layer {
  name: "conv6_2"
  type: "Convolution"
  bottom: "conv6_1"
  top: "conv6_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_2_relu"
  type: "ReLU"
  bottom: "conv6_2"
  top: "conv6_2"
}
layer {
  name : "conv6_2_bn"
  type : "BatchNorm"  include { phase: TRAIN}
  batch_norm_param {
    use_global_stats: false 
    moving_average_fraction: 0.95
  }
  top : "conv6_2"
  bottom : "conv6_2"
}
layer {
  name : "conv6_2_bn"
  type : "BatchNorm"  include { phase: TEST}
  batch_norm_param {
    use_global_stats: true 
    moving_average_fraction: 0.95
  }
  top : "conv6_2"
  bottom : "conv6_2"
}
layer {
  name: "conv7_1"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv7_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_1_relu"
  type: "ReLU"
  bottom: "conv7_1"
  top: "conv7_1"
}
layer {
  name : "conv7_1_bn"
  type : "BatchNorm"  include { phase: TRAIN}
  batch_norm_param {
    use_global_stats: false 
    moving_average_fraction: 0.95
  }
  top : "conv7_1"
  bottom : "conv7_1"
}
layer {
  name : "conv7_1_bn"
  type : "BatchNorm"  include { phase: TEST}
  batch_norm_param {
    use_global_stats: true 
    moving_average_fraction: 0.95
  }
  top : "conv7_1"
  bottom : "conv7_1"
}
layer {
  name: "conv7_2"
  type: "Convolution"
  bottom: "conv7_1"
  top: "conv7_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_2_relu"
  type: "ReLU"
  bottom: "conv7_2"
  top: "conv7_2"
}
layer {
  name : "conv7_2_bn"
  type : "BatchNorm"  include { phase: TRAIN}
  batch_norm_param {
    use_global_stats: false 
    moving_average_fraction: 0.95
  }
  top : "conv7_2"
  bottom : "conv7_2"
}
layer {
  name : "conv7_2_bn"
  type : "BatchNorm"  include { phase: TEST}
  batch_norm_param {
    use_global_stats: true 
    moving_average_fraction: 0.95
  }
  top : "conv7_2"
  bottom : "conv7_2"
}
layer {
  name: "conv8_1"
  type: "Convolution"
  bottom: "conv7_2"
  top: "conv8_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_1_relu"
  type: "ReLU"
  bottom: "conv8_1"
  top: "conv8_1"
}
layer {
  name : "conv8_1_bn"
  type : "BatchNorm"  include { phase: TRAIN}
  batch_norm_param {
    use_global_stats: false 
    moving_average_fraction: 0.95
  }
  top : "conv8_1"
  bottom : "conv8_1"
}
layer {
  name : "conv8_1_bn"
  type : "BatchNorm"  include { phase: TEST}
  batch_norm_param {
    use_global_stats: true 
    moving_average_fraction: 0.95
  }
  top : "conv8_1"
  bottom : "conv8_1"
}
layer {
  name: "conv8_2"
  type: "Convolution"
  bottom: "conv8_1"
  top: "conv8_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_2_relu"
  type: "ReLU"
  bottom: "conv8_2"
  top: "conv8_2"
}
layer {
  name : "conv8_2_bn"
  type : "BatchNorm"  include { phase: TRAIN}
  batch_norm_param {
    use_global_stats: false 
    moving_average_fraction: 0.95
  }
  top : "conv8_2"
  bottom : "conv8_2"
}
layer {
  name : "conv8_2_bn"
  type : "BatchNorm"  include { phase: TEST}
  batch_norm_param {
    use_global_stats: true 
    moving_average_fraction: 0.95
  }
  top : "conv8_2"
  bottom : "conv8_2"
}
layer {
  name: "pool6"
  type: "Pooling"
  bottom: "conv8_2"
  top: "pool6"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}





layer {
  name: "conv4_3_norm_1"
  type: "Normalize"
  bottom: "fire5/concat"
  top: "conv4_3_norm_1"
  norm_param {
    across_spatial: false
    scale_filler {
      type: "constant"
      value: 20
    }
    channel_shared: false
  }
}
layer {
  name: "conv4_3_norm_mbox_loc_1"
  type: "Convolution"
  bottom: "conv4_3_norm_1"
  top: "conv4_3_norm_mbox_loc_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 40 #24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_3_norm_mbox_loc_perm_1"
  type: "Permute"
  bottom: "conv4_3_norm_mbox_loc_1"
  top: "conv4_3_norm_mbox_loc_perm_1"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_loc_flat_1"
  type: "Flatten"
  bottom: "conv4_3_norm_mbox_loc_perm_1"
  top: "conv4_3_norm_mbox_loc_flat_1"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_conf_0"
  type: "Convolution"
  bottom: "conv4_3_norm_1"
  top: "conv4_3_norm_mbox_conf_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
  #propagate_down: false
}

layer {
  name: "conv4_3_norm_mbox_conf_0_relu"
  type: "ReLU"
  bottom: "conv4_3_norm_mbox_conf_0"
  top: "conv4_3_norm_mbox_conf_0"
}

layer {
  name : "conv4_3_norm_mbox_conf_0_bn"
  type : "BatchNorm"  include { phase: TRAIN}
  batch_norm_param {
    use_global_stats: false 
    moving_average_fraction: 0.95
  }
  top : "conv4_3_norm_mbox_conf_0"
  bottom : "conv4_3_norm_mbox_conf_0"
}

layer {
  name : "conv4_3_norm_mbox_conf_0_bn"
  type : "BatchNorm"  include { phase: TEST}
  batch_norm_param {
    use_global_stats: true 
    moving_average_fraction: 0.95
  }
  top : "conv4_3_norm_mbox_conf_0"
  bottom : "conv4_3_norm_mbox_conf_0"
}

layer {
  name: "conv4_3_norm_mbox_conf_2"
  type: "Convolution"
  bottom: "conv4_3_norm_mbox_conf_0"
  top: "conv4_3_norm_mbox_conf_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "conv4_3_norm_mbox_conf_2_relu"
  type: "ReLU"
  bottom: "conv4_3_norm_mbox_conf_2"
  top: "conv4_3_norm_mbox_conf_2"
}

layer {
  name : "conv4_3_norm_mbox_conf_2_bn"
  type : "BatchNorm"  include { phase: TRAIN}
  batch_norm_param {
    use_global_stats: false 
    moving_average_fraction: 0.95
  }
  top : "conv4_3_norm_mbox_conf_2"
  bottom : "conv4_3_norm_mbox_conf_2"
}

layer {
  name : "conv4_3_norm_mbox_conf_2_bn"
  type : "BatchNorm"  include { phase: TEST}
  batch_norm_param {
    use_global_stats: true 
    moving_average_fraction: 0.95
  }
  top : "conv4_3_norm_mbox_conf_2"
  bottom : "conv4_3_norm_mbox_conf_2"
}


layer {
  name: "conv4_3_norm_mbox_conf_3"
  type: "Convolution"
  bottom: "conv4_3_norm_mbox_conf_2"
  top: "conv4_3_norm_mbox_conf_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 20 #12
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "conv4_3_norm_mbox_conf_perm_1"
  type: "Permute"
  bottom: "conv4_3_norm_mbox_conf_3"
  top: "conv4_3_norm_mbox_conf_perm_1"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_conf_flat_1"
  type: "Flatten"
  bottom: "conv4_3_norm_mbox_conf_perm_1"
  top: "conv4_3_norm_mbox_conf_flat_1"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_priorbox_1"
  type: "PriorBox"
  bottom: "conv4_3_norm_1"
  bottom: "data"
  top: "conv4_3_norm_mbox_priorbox_1"
  prior_box_param {
    min_size: 15.0
    max_size: 25.0
    min_size: 25.0
    max_size: 51.0
    aspect_ratio: 0.25
    aspect_ratio: 0.33
    aspect_ratio: 0.5
    aspect_ratio: 0.75
    flip: false
    clip: true
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
  }
}
layer {
  name: "fc7_mbox_loc_1"
  type: "Convolution"
  bottom: "fire9/concat"
  top: "fc7_mbox_loc_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 40
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc7_mbox_loc_perm_1"
  type: "Permute"
  bottom: "fc7_mbox_loc_1"
  top: "fc7_mbox_loc_perm_1"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "fc7_mbox_loc_flat_1"
  type: "Flatten"
  bottom: "fc7_mbox_loc_perm_1"
  top: "fc7_mbox_loc_flat_1"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "fc7_mbox_conf_1"
  type: "Convolution"
  bottom: "fire9/concat"
  top: "fc7_mbox_conf_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 20
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc7_mbox_conf_perm_1"
  type: "Permute"
  bottom: "fc7_mbox_conf_1"
  top: "fc7_mbox_conf_perm_1"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "fc7_mbox_conf_flat_1"
  type: "Flatten"
  bottom: "fc7_mbox_conf_perm_1"
  top: "fc7_mbox_conf_flat_1"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "fc7_mbox_priorbox_1"
  type: "PriorBox"
  bottom: "fire9/concat"
  bottom: "data"
  top: "fc7_mbox_priorbox_1"
  prior_box_param {
    min_size: 34.0
    max_size: 51.0
    min_size: 51.0
    max_size: 97.0
    aspect_ratio: 0.25
    aspect_ratio: 0.33
    aspect_ratio: 0.5
    aspect_ratio: 0.75
    flip: false
    clip: true
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
  }
}
layer {
  name: "conv6_2_mbox_loc_1"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv6_2_mbox_loc_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 20
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_2_mbox_loc_perm_1"
  type: "Permute"
  bottom: "conv6_2_mbox_loc_1"
  top: "conv6_2_mbox_loc_perm_1"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv6_2_mbox_loc_flat_1"
  type: "Flatten"
  bottom: "conv6_2_mbox_loc_perm_1"
  top: "conv6_2_mbox_loc_flat_1"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv6_2_mbox_conf_1"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv6_2_mbox_conf_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 10
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_2_mbox_conf_perm_1"
  type: "Permute"
  bottom: "conv6_2_mbox_conf_1"
  top: "conv6_2_mbox_conf_perm_1"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv6_2_mbox_conf_flat_1"
  type: "Flatten"
  bottom: "conv6_2_mbox_conf_perm_1"
  top: "conv6_2_mbox_conf_flat_1"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv6_2_mbox_priorbox_1"
  type: "PriorBox"
  bottom: "conv6_2"
  bottom: "data"
  top: "conv6_2_mbox_priorbox_1"
  prior_box_param {
    min_size: 97.0
    max_size: 138.0
    aspect_ratio: 0.25
    aspect_ratio: 0.33
    aspect_ratio: 0.5
    aspect_ratio: 0.75
    flip: false
    clip: true
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
  }
}
layer {
  name: "conv7_2_mbox_loc_1"
  type: "Convolution"
  bottom: "conv7_2"
  top: "conv7_2_mbox_loc_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 20
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_2_mbox_loc_perm_1"
  type: "Permute"
  bottom: "conv7_2_mbox_loc_1"
  top: "conv7_2_mbox_loc_perm_1"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv7_2_mbox_loc_flat_1"
  type: "Flatten"
  bottom: "conv7_2_mbox_loc_perm_1"
  top: "conv7_2_mbox_loc_flat_1"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv7_2_mbox_conf_1"
  type: "Convolution"
  bottom: "conv7_2"
  top: "conv7_2_mbox_conf_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 10
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_2_mbox_conf_perm_1"
  type: "Permute"
  bottom: "conv7_2_mbox_conf_1"
  top: "conv7_2_mbox_conf_perm_1"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv7_2_mbox_conf_flat_1"
  type: "Flatten"
  bottom: "conv7_2_mbox_conf_perm_1"
  top: "conv7_2_mbox_conf_flat_1"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv7_2_mbox_priorbox_1"
  type: "PriorBox"
  bottom: "conv7_2"
  bottom: "data"
  top: "conv7_2_mbox_priorbox_1"
  prior_box_param {
    min_size: 138.0
    max_size: 184.0
    aspect_ratio: 0.25
    aspect_ratio: 0.33
    aspect_ratio: 0.5
    aspect_ratio: 0.75
    flip: false
    clip: true
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
  }
}
layer {
  name: "conv8_2_mbox_loc_1"
  type: "Convolution"
  bottom: "conv8_2"
  top: "conv8_2_mbox_loc_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 20
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_2_mbox_loc_perm_1"
  type: "Permute"
  bottom: "conv8_2_mbox_loc_1"
  top: "conv8_2_mbox_loc_perm_1"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv8_2_mbox_loc_flat_1"
  type: "Flatten"
  bottom: "conv8_2_mbox_loc_perm_1"
  top: "conv8_2_mbox_loc_flat_1"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv8_2_mbox_conf_1"
  type: "Convolution"
  bottom: "conv8_2"
  top: "conv8_2_mbox_conf_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 10
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_2_mbox_conf_perm_1"
  type: "Permute"
  bottom: "conv8_2_mbox_conf_1"
  top: "conv8_2_mbox_conf_perm_1"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv8_2_mbox_conf_flat_1"
  type: "Flatten"
  bottom: "conv8_2_mbox_conf_perm_1"
  top: "conv8_2_mbox_conf_flat_1"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv8_2_mbox_priorbox_1"
  type: "PriorBox"
  bottom: "conv8_2"
  bottom: "data"
  top: "conv8_2_mbox_priorbox_1"
  prior_box_param {
    min_size: 184.0
    max_size: 230.0
    aspect_ratio: 0.25
    aspect_ratio: 0.33
    aspect_ratio: 0.5
    aspect_ratio: 0.75
    flip: false
    clip: true
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
  }
}
layer {
  name: "pool6_mbox_loc_1"
  type: "Convolution"
  bottom: "pool6"
  top: "pool6_mbox_loc_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 20
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool6_mbox_loc_perm_1"
  type: "Permute"
  bottom: "pool6_mbox_loc_1"
  top: "pool6_mbox_loc_perm_1"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "pool6_mbox_loc_flat_1"
  type: "Flatten"
  bottom: "pool6_mbox_loc_perm_1"
  top: "pool6_mbox_loc_flat_1"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "pool6_mbox_conf_1"
  type: "Convolution"
  bottom: "pool6"
  top: "pool6_mbox_conf_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 10
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool6_mbox_conf_perm_1"
  type: "Permute"
  bottom: "pool6_mbox_conf_1"
  top: "pool6_mbox_conf_perm_1"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "pool6_mbox_conf_flat_1"
  type: "Flatten"
  bottom: "pool6_mbox_conf_perm_1"
  top: "pool6_mbox_conf_flat_1"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "pool6_mbox_priorbox_1"
  type: "PriorBox"
  bottom: "pool6"
  bottom: "data"
  top: "pool6_mbox_priorbox_1"
  prior_box_param {
    min_size: 230.0
    max_size: 276.0
    aspect_ratio: 0.25
    aspect_ratio: 0.33
    aspect_ratio: 0.5
    aspect_ratio: 0.75
    flip: false
    clip: true
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
  }
}
layer {
  name: "mbox_loc_1"
  type: "Concat"
  bottom: "conv4_3_norm_mbox_loc_flat_1"
  bottom: "fc7_mbox_loc_flat_1"
  bottom: "conv6_2_mbox_loc_flat_1"
  bottom: "conv7_2_mbox_loc_flat_1"
  bottom: "conv8_2_mbox_loc_flat_1"
  bottom: "pool6_mbox_loc_flat_1"
  top: "mbox_loc_1"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_conf_1"
  type: "Concat"
  bottom: "conv4_3_norm_mbox_conf_flat_1"
  bottom: "fc7_mbox_conf_flat_1"
  bottom: "conv6_2_mbox_conf_flat_1"
  bottom: "conv7_2_mbox_conf_flat_1"
  bottom: "conv8_2_mbox_conf_flat_1"
  bottom: "pool6_mbox_conf_flat_1"
  top: "mbox_conf_1"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_priorbox_1"
  type: "Concat"
  bottom: "conv4_3_norm_mbox_priorbox_1"
  bottom: "fc7_mbox_priorbox_1"
  bottom: "conv6_2_mbox_priorbox_1"
  bottom: "conv7_2_mbox_priorbox_1"
  bottom: "conv8_2_mbox_priorbox_1"
  bottom: "pool6_mbox_priorbox_1"
  top: "mbox_priorbox_1"
  concat_param {
    axis: 2
  }
}
layer {
  name: "mbox_loss_1"
  type: "MultiBoxLoss"
  bottom: "mbox_loc_1"
  bottom: "mbox_conf_1"
  bottom: "mbox_priorbox_1"
  bottom: "label"
  top: "mbox_loss_1"
  include {
    phase: TRAIN
  }
  propagate_down: true
  propagate_down: true
  propagate_down: false
  propagate_down: false
  loss_param {
    normalization: VALID # FULL VALID BATCH_SIZE NONE
  }
  multibox_loss_param {
    loc_loss_type: SMOOTH_L1
	
    conf_loss_type: FocalLoss #SOFTMAX LOGISTIC FocalLoss 
    fl_alpha: 0.75
    fl_gamma:  2.0
	
    loc_weight: 1.0
    num_classes: 2
    share_location: true
    match_type: PER_PREDICTION
    overlap_threshold: 0.5
    use_prior_for_matching: true
    background_label_id: 0
	#ignore_label_id: 13
    use_difficult_gt: true
    #do_neg_mining: true
    neg_pos_ratio: 3.0
    neg_overlap: 0.35
    code_type: CENTER_SIZE
	mining_type: NONE #HARD_EXAMPLE MAX_NEGATIVE NONE
  }
}
